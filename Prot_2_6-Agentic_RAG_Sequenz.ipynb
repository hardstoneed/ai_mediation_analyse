{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argentic RAG \n",
    "Dieser Prototyp untersucht die Fähigkeiten von LLM unterstützen Multiagent System für eine Sequenzanalyse \n",
    "\n",
    "Als Framework wird crewai verwendet. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" %pip install crewai\n",
    "%pip install load_dotenv\n",
    "%pip install os\n",
    "%pip install crewai[tools]\n",
    "%pip install agentops\n",
    "%pip install langchain_openai \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup der Fachfragen an die Transkripte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fall = \"F5\"\n",
    "Text = \"I1: Moment erstmal. (9) Ich komm mir so herzlos vor, wenn ich jetzt auf die Struktur zurückführe. Aber trotzdem, wollen Sie dazu überhaupt eine Antwort haben? #02:32:14-7#\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisierung der Dokumente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process \n",
    "import os\n",
    "from crewai_tools import DirectorySearchTool, PDFSearchTool, SerperDevTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_MODEL_NAME\"]=\"gpt-4o\"\n",
    "\n",
    "doctool = DirectorySearchTool(directory=f'anon\\\\F5')\n",
    "\n",
    "import agentops\n",
    "agentops.init()# Update pip\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starten der Untersuchung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = time.time() \n",
    "\n",
    "Sequenzer = Agent(\n",
    "    role = 'Sequenzer',\n",
    "    goal = \"Dein Ziel ist die Aufteilung eines gegebenen Textes in Sequenzen, hierbei sollen Satzzeichen, Pausen (3) und Sinngrenzen beachtung finden.\"\n",
    "           \"Keine Beachtung finden die Sprecher markierung und der Zeitstempel am Ende.\",\n",
    "    backstory = 'Du bist Sequenzierungsprofi und kennst die Techniken der Objektiven Hermeneutik und kannst diese Anwenden',\n",
    "    verbose = True,\n",
    "    allow_delegation= False,\n",
    "    \n",
    ")\n",
    "\n",
    "Storyteller = Agent(\n",
    "    role = 'Geschichtenerzähler',\n",
    "    goal = \"Ziel ist es, mindestens vier vielfältige und phantasievolle Geschichten für jede Sequenz zu schaffen.\"\n",
    "            \"Diese Geschichten sollten eine Reihe von Kontexten abdecken, um eine breite Basis für die Interpretation zu schaffen.\",\n",
    "    backstory = 'Du bist eine Kreativer Geschichten Schreiber ',\n",
    "    verbose = True,\n",
    "    allow_delegation= False,\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4o\", temperature=0.9)\n",
    "   \n",
    ")\n",
    "\n",
    "Interpreter = Agent(\n",
    "    role = 'Interpreter',\n",
    "    goal = 'Ziel gemeinsame Themen oder Interpretationen ',\n",
    "    backstory = 'Der Interpreter analysiert die vom Geschichtenerzähler geschaffenen Geschichten und leitet daraus gemeinsame Themen oder Interpretationen ab.'\n",
    "                'Dies beinhaltet die Identifizierung von zugrunde liegenden Mustern und Bedeutungen, die in den verschiedenen Geschichten übereinstimmen.',\n",
    "    verbose = True,\n",
    "    allow_delegation= False,\n",
    "    )\n",
    "\n",
    "Contextualizer = Agent(\n",
    "    role = 'Kontextualizer',\n",
    "    goal = 'Ziel ist ein vergleich der Interpretationen mit dem realen Kontext.',\n",
    "    backstory = 'Der Kontextualisierer vergleicht die vom Interpreten abgeleiteten Interpretationen mit einem bestimmten realen Kontext.'\n",
    "                'Dabei wird bewertet, wie gut die Interpretationen mit der tatsächlichen Situation übereinstimmen, und es werden Erkenntnisse über die Relevanz und Genauigkeit der Interpretationen gewonnen.',\n",
    "    verbose = True,\n",
    "    allow_delegation= False,\n",
    "    tools = [doctool]\n",
    "    )\n",
    "\n",
    "\n",
    "sequence_task = Task(\n",
    "    description=f'Sequenziere den Text: \\\" {Text} \\\" in Sinnabschnitte, wobei auch die Pausen, markiert durch Klammern z.B. (5) Beachtung finden sollen ',\n",
    "    expected_output='Eine Liste mit Sequenzen. ', \n",
    "    agent=Sequenzer,\n",
    "    output_file= f\"Ergebnisse\\\\{Fall}\\\\{timestamp}_{Fall}_aRAG_Seq_Sequenz.txt\",\n",
    "    )\n",
    "    \n",
    "\n",
    "storytelling_task  = Task( \n",
    "    description=f'Erstelle vier kreative Geschichten zu jeder Sequenz!',\n",
    "    expected_output='Eine Liste von Geschichten, die verschiedene Kontexte und Szenarien für jede Sequenz', \n",
    "    agent=Storyteller,\n",
    "    Context=sequence_task, \n",
    "  # tools=[doctool],\n",
    "    output_file= f\"Ergebnisse\\\\{Fall}\\\\{timestamp}_{Fall}_aRAG_Seq_Storytelling.txt\")\n",
    "\n",
    "interpretation_task = Task( \n",
    "    description= 'Analysiere die vom Geschichtenerzähler geschaffenen Geschichten und leitet daraus gemeinsame Themen oder Interpretationen ab!',\n",
    "    expected_output=f'Ziel gemeinsame Themen oder Interpretationen', \n",
    "    agent=Interpreter,\n",
    "   # tools=[doctool], \n",
    "    output_file= f\"Ergebnisse\\\\{Fall}\\\\{timestamp}_{Fall}_aRAG_Seq_Interpreter.txt\")\n",
    "\n",
    "context_confrontation_task = Task( \n",
    "    description= 'Vergleiche die Interpretationen mit einem bestimmten realen Kontext.'\n",
    "                 'Bewerte wie gut die Interpretationen mit der tatsächlichen Situation übereinstimmen, und ermittle die Relevanz und Genauigkeit der Interpretationen.',\n",
    "    expected_output=f' Ein detaillierter Vergleich der Interpretationen mit dem realen Kontext, der die Übereinstimmung und eventuelle Abweichungen hervorhebt', \n",
    "    agent=Contextualizer,\n",
    "    tools=[doctool], \n",
    "    output_file= f\"Ergebnisse\\\\{Fall}\\\\{timestamp}_{Fall}_aRAG_Seq_Confrontation.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form the crew with a sequential process\n",
    "hier_report_crew = Crew(\n",
    "  agents=[Sequenzer, Storyteller, Interpreter, Contextualizer],\n",
    "  tasks=[sequence_task, storytelling_task, interpretation_task,context_confrontation_task],\n",
    "  process=Process.hierarchical,\n",
    "  manager_llm=ChatOpenAI(temperature=0, model=\"gpt-4o\"),\n",
    "  verbose=2,\n",
    "  memory=False,\n",
    "  cache=True,\n",
    "  share_crew=False,\n",
    "  full_output=True,\n",
    "  output_log_file=True,\n",
    "  language = \"de\",\n",
    "  language_File = \"de.json\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starten der Untersuchung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#result = report_crew.kickoff(inputs={\"directory\": f'anon\\\\{Fall}'})\n",
    "result = hier_report_crew.kickoff(inputs={'Text':Text , 'timestamp': timestamp })\n",
    "#result_seq = seq_report_crew.kickoff(Text)\n",
    "print(\"######################\")\n",
    "print(result)\n",
    "print(\"######################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hier_report_crew.usage_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".evli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
